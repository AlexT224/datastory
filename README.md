# Exploring Queer

## Why
Using Twarc, I decided to collect tweets that contain the word ‘queer’. I didn’t modify the search in any way because I knew that I would only get tweets from the last two weeks anyway. I didn’t add any other words to limit the search because I was curious as to how the word has been used by itself on Twitter. These days, queer still means a lot of different things to different people. It could be seen as an insult, an umbrella term, a word of empowerment, or any other interpretation that someone has, and I didn’t want to limit my results and lose any of those interpretations. I have been interested lately in how queer identities are formed online and how they communicate with one another and I thought that this data set would provide some insight into that. I did not let the program run in its entirety when collecting the data because I didn’t want a data set that was too long. In the end, I came away with 11,904 tweets and those were only from the day that I collected on (Tuesday, May 1st) between 2:30 AM and 7:44 PM.  

## How
The questions that I would like to ask are generally in the area of how people are talking about the word ‘queer’ and what are the different things that can impact that. We learned how to use GoogleSheets in class but I also know how to use NVivo so I thought it would be interesting to compare the different answers I would be able to get from the two of them. In terms of analyzing text, I think that NVivo is a lot handier since it was partly created to analyze large amounts of text. Being able to code certain words and phrases together is something that gives NVivo and major foot up over GoogleSheets. Also, GoogleSheets doesn’t allow you to easily read the actual tweet in the way that NVivo does which gives NVivo an advantage. If I wanted to answer questions dealing with the number count of words, hashtags, or usernames GoogleSheets is a lot more helpful. From what I can tell, NVivo isn’t meant for that sort of thing in the way that GoogleSheets is. Especially not with a dataset so large. For example, I noticed that Twarc gathered tweets from people that had the word ‘queer’ in their username but that didn’t actually have a tweet containing the word. Through GoogleSheets I am able to see how many times those users tweeted out of the overall 11,904 tweets. I could not do that on NVivo because it doesn’t have the same level of filtering. Another limitation that NVivo has is that it had trouble reading the .csv file and I had to change and upload it as an Excel file. It then automatically read the data as a survey rather than tweets which lead to me having less of the perks that come with analyzing Twitter data in NVivo like premade charts and word trees. I could have just used NCapture to gather the tweets but it doesn’t gather as much information that Twarc does. 


The main ethical question that this dataset raises for me is: what do you cut out? I gathered over eleven thousand tweets that were only from one day. That dataset is too large to do much in-depth analysis on. My first thought would be to take out the tweets from people that just had ‘queer’ in their username but those tweets do tell me something about how people are using and talking about the word. You can’t take in every voice but then it’s really hard to decide whose to cut out. I think scholarship has its own form of ‘digital redlining’ by usually only using the voices that are the clearest or loudest to make their points while overshadowing the other people that contributed to the study. This is not an easy question for studying social media because with a dataset so large, how could you not overshadow some of them? 

## Data Links

A link to my [data](https://github.com/AlexT224/datastory/raw/master/data/queertwarcresults.csv)


